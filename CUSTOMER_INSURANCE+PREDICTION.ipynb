{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sathyadev75/DS_PROJECTS_PRAKASH/blob/main/CUSTOMER_INSURANCE%2BPREDICTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VHlcaQ4W58R"
      },
      "outputs": [],
      "source": [
        "\"\"\"Guvi Datathon 1.0 Customer Conversion Prediction Problem Statement You are working for a new-age insurance company and employ multiple outreach plans to sell term insurance to your customers. Telephonic marketing campaigns still remain one of the most effective ways to reach out to people however they incur a lot of cost. Hence, it is important to identify the customers that are most likely to convert beforehand so that they can be specifically targeted via call. We are given the historical marketing data of the insurance company and are required to build a ML model that will predict if a client will subscribe to the insurance. Data The historical sales data is available as a compressed file here. Data Features: ● age (numeric) ● job : type of job ● marital : marital status ● educational_qual : education status ● call_type : contact communication type ● day: last contact day of the month (numeric) ● mon: last contact month of year ● dur: last contact duration, in seconds (numeric) ● num_calls: number of contacts performed during this campaign and for this client ● prev_outcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\") Output variable (desired target): ● y - has the client subscribed to the insurance? Minimum Requirements It is not sufficient to just fit a model - the model must be analysed to find the important factors that contribute towards the price. AUROC must be used as a metric to evaluate the performance of the models\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q3PNa_P9AHB"
      },
      "source": [
        "\"\"\"Guvi Datathon 1.0\n",
        "Customer Conversion Prediction\n",
        "Problem Statement\n",
        "You are working for a new-age insurance company and employ\n",
        "multiple outreach plans to sell term insurance to your\n",
        "customers. Telephonic marketing campaigns still remain one of\n",
        "the most effective ways to reach out to people however they\n",
        "incur a lot of cost. Hence, it is important to identify the\n",
        "customers that are most likely to convert beforehand so that\n",
        "they can be specifically targeted via call. We are given the\n",
        "historical marketing data of the insurance company and are\n",
        "required to build a ML model that will predict if a client will\n",
        "subscribe to the insurance.\n",
        "Data\n",
        "The historical sales data is available as a compressed file here.\n",
        "Data\n",
        "Features:\n",
        "● age (numeric)\n",
        "● job : type of job\n",
        "● marital : marital status\n",
        "● educational_qual : education status\n",
        "● call_type : contact communication type\n",
        "● day: last contact day of the month (numeric)\n",
        "● mon: last contact month of year\n",
        "● dur: last contact duration, in seconds (numeric)\n",
        "● num_calls: number of contacts performed during this\n",
        "campaign and for this client\n",
        "● prev_outcome: outcome of the previous marketing\n",
        "campaign (categorical:\n",
        "\"unknown\",\"other\",\"failure\",\"success\")\n",
        "Output variable (desired target):\n",
        "● y - has the client subscribed to the insurance?\n",
        "Minimum Requirements\n",
        "It is not sufficient to just fit a model - the model must be\n",
        "analysed to find the important factors that contribute towards\n",
        "the price. AUROC must be used as a metric to evaluate the\n",
        "performance of the models\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRmrNM-C9E-6"
      },
      "outputs": [],
      "source": [
        "#required packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statistics as st\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4qB0u2DDPOg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbQNXWJH9Wfs"
      },
      "outputs": [],
      "source": [
        "#IMPORTNG DATAFRAME\n",
        "\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/DATA SCIENCE PROJECTS/CUSTOMER INSURANCE PREDICTION/Customer Conversion Prediction - Customer Conversion Prediction.csv\")\n",
        "\n",
        "df1=df.head(4)\n",
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLDuuOpr-HhS"
      },
      "outputs": [],
      "source": [
        "#checking null value\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3-XpxPNDVX7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwE6qmrFjm76"
      },
      "outputs": [],
      "source": [
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPtGKZO3j1g3"
      },
      "outputs": [],
      "source": [
        "sns.set_style('darkgrid')\n",
        "sns.countplot(data=df,x='y')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PKBzLH-98pt"
      },
      "source": [
        "**DATA CLEANING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mr1-JNuz-FMR"
      },
      "outputs": [],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_hLSQq9-inS"
      },
      "outputs": [],
      "source": [
        "#classification problem \n",
        "\n",
        "print(df.shape)\n",
        "print(f'➤ The DataFrame(df) contains {df.shape[0]} rows and {df.shape[1]} columns.')\n",
        "\n",
        "\n",
        "df.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNJgq3WfF-AY"
      },
      "outputs": [],
      "source": [
        "list_columns=df.columns\n",
        "for column in list_columns:\n",
        "  print(df[column].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpthzH4kGOxZ"
      },
      "source": [
        "since null values are present in string form \"unknown\" we need to replace it to null values and then filled not to loose th huge amount of values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iHYVuA6_tdN"
      },
      "outputs": [],
      "source": [
        "df.columns\n",
        "#converting unknown values to None in which it will able to filled by numpy\n",
        "\n",
        "df[\"prev_outcome\"]=df[\"prev_outcome\"].replace({\"unknown\":None})\n",
        "\n",
        "df[\"job\"]=df[\"job\"].replace({\"unknown\":None})\n",
        "\n",
        "df[\"education_qual\"]=df[\"education_qual\"].replace({\"unknown\":None})\n",
        "\n",
        "df[\"call_type\"]=df[\"call_type\"].replace({\"unknown\":None})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYhzs6Cj_XZM"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXDZcQRKHu_u"
      },
      "outputs": [],
      "source": [
        "#filling missing values using most frquent values in respective columns\n",
        "\n",
        "\n",
        "\n",
        "df[\"job\"]=df[\"job\"].replace({None:st.mode(df[\"job\"])})\n",
        "\n",
        "df[\"education_qual\"]=df[\"education_qual\"].replace({None:st.mode(df[\"education_qual\"])})\n",
        "\n",
        "df[\"call_type\"]=df[\"call_type\"].replace({None:st.mode(df[\"call_type\"])})\n",
        "\n",
        "\n",
        "#st.mode(df[\"prev_outcome\"])    #since mode is None we select other than this\n",
        "\n",
        "print(df[\"prev_outcome\"].value_counts())  #most occuriing element is elected other than None\n",
        "\n",
        "#from the count we get \"failure\" is most occured one  4901\n",
        "\n",
        "df[\"prev_outcome\"]=df[\"prev_outcome\"].replace({None:\"failure\"})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6JfMwAcs6tz"
      },
      "outputs": [],
      "source": [
        "list=df.columns\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dn2LsZAgxDuX"
      },
      "outputs": [],
      "source": [
        "for column in list:\n",
        "  print(df[column].unique()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzESFipaOO8a"
      },
      "source": [
        "**verification of null value presence**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAzu8qfRS5lr"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZHxeWn7TDlV"
      },
      "outputs": [],
      "source": [
        "df=df.drop_duplicates()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKLshnx2uoSt"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxFFLzKUTqn4"
      },
      "source": [
        "DATA VISUALIZATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHy-huXQT57N"
      },
      "source": [
        "CATEGORICAL VARIABLE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "387wJ04yJ3C9"
      },
      "outputs": [],
      "source": [
        "#since day in month is also a categorical variable  \n",
        "# a distinct category within the range of possible values\n",
        "\n",
        "df[\"day\"]=df[\"day\"].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WteFHlmeGunM"
      },
      "outputs": [],
      "source": [
        "list_cat_vars=[column for column in df.columns if df[column].dtype==object]\n",
        "print(\"categorical_columns: \\n\",list_cat_vars)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qpz3GRCQ9RSw"
      },
      "outputs": [],
      "source": [
        "for i in list_cat_vars:\n",
        "  print(type(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RkU5aGUJ_Jw"
      },
      "outputs": [],
      "source": [
        "#job,marital,education_qual,call_type,prev_outcome mon\n",
        "#list_cat_vars\n",
        "\n",
        "#for categorical columns\n",
        "plots=431\n",
        "sns.set_theme(style='darkgrid',palette='pastel')\n",
        "plt.figure(figsize=(20,25))\n",
        "list_cat_vars.remove(\"y\")\n",
        "\n",
        "for cat_column in list_cat_vars:\n",
        "\n",
        "      plt.subplot(plots)\n",
        "      sns.set(style=\"darkgrid\")\n",
        "      sns.countplot(x=cat_column,hue=\"y\",data=df)\n",
        "      plt.xlabel(cat_column, color=\"blue\")\n",
        "      plt.ylabel(\"result\", color=\"red\")\n",
        "      plots+=1\n",
        "      if cat_column==\"day\":\n",
        "          plt.xticks(rotation=90)\n",
        "      if cat_column==\"num_calls\":\n",
        "          plt.xlim(0,4)\n",
        "      if cat_column==\"job\":\n",
        "          plt.xticks(rotation=90)\n",
        "      if cat_column==\"job\":\n",
        "          plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4fRYIzpMfsb"
      },
      "outputs": [],
      "source": [
        "#LIST OF CATEGORICAL COLUMNS\n",
        "list_cat_vars\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qczmt1vZCp9A"
      },
      "source": [
        "from the plots we can understand that change in categorical variable has some amount of impact on target variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Apz5yFWojHC"
      },
      "source": [
        "CONTINOUS VARIABLE VS TARGET VARIABLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7YVfmKXoR_u"
      },
      "outputs": [],
      "source": [
        "#LIST OF CONTINOUS COLUMNS\n",
        "\n",
        "list_con_vars=[column for column in df.columns if df[column].dtype==\"int64\"]\n",
        "print(list_con_vars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKGRrdwLCrdD"
      },
      "source": [
        "**REMOVING OUTLIERS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MVO6y_bOLQU"
      },
      "outputs": [],
      "source": [
        "list_con_vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hFDVZz5XBCJ"
      },
      "outputs": [],
      "source": [
        "#job,marital,education_qual,call_type,prev_outcome mon\n",
        "#list_cat_vars\n",
        "\n",
        "#for categorical columns\n",
        "from scipy.stats import stats\n",
        "plots=431\n",
        "sns.set_theme(style='darkgrid',palette='pastel')\n",
        "plt.figure(figsize=(20,25))\n",
        "\n",
        "con_col_vars=[\"age\",\"dur\",\"num_calls\"]\n",
        "for cat_column in con_col_vars:\n",
        "\n",
        "      plt.subplot(plots)\n",
        "      sns.set(style=\"darkgrid\")\n",
        "      sns.boxplot(x=cat_column, y=\"y\", data=df)\n",
        "      plt.xlabel(cat_column, color=\"blue\")\n",
        "      plt.ylabel(\"values\", color=\"red\")\n",
        "      plots+=1\n",
        "      \n",
        "      \n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "sns.set_theme(style='darkgrid',palette='pastel')\n",
        "plt.figure(figsize=(20,25))\n",
        "\n",
        "for cat_column in con_col_vars:\n",
        "\n",
        "      plt.subplot(plots)\n",
        "      sns.set(style=\"darkgrid\")\n",
        "      df[\"z_score\"]=stats.zscore(df[cat_column])\n",
        "      df=df[df[\"z_score\"]>-3]\n",
        "      df=df[df[\"z_score\"]<3]\n",
        "      sns.boxplot(x=cat_column, y=\"y\", data=df)\n",
        "      plt.xlabel(cat_column, color=\"blue\")\n",
        "      plt.ylabel(\"values\", color=\"red\")\n",
        "      plots+=1\n",
        "      \n",
        "      \n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnmdzW2ikv7c"
      },
      "source": [
        "the plots indicates that\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okKwyv9O-Dif"
      },
      "outputs": [],
      "source": [
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neskAYFnot8Y"
      },
      "outputs": [],
      "source": [
        "#age,dur\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_theme(style='darkgrid',palette='pastel')\n",
        "\n",
        "plt.figure(figsize=(20,25))\n",
        "\n",
        "\n",
        "plt.subplot(431)\n",
        "sns.countplot(x=\"dur\", hue=\"y\",data=df)\n",
        "plt.xlim(171,180)\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(432)\n",
        "sns.countplot(x=\"age\", hue=\"y\",data=df)\n",
        "plt.xlim(20,35)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the IQR and define the outlier threshold\n",
        "Q1 = df[\"num_calls\"].quantile(0.25)\n",
        "Q3 = df[\"num_calls\"].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "threshold = 1.5 * IQR\n",
        "\n",
        "# Filter the data to remove outliers\n",
        "df= df[(df[\"num_calls\"] >= Q1 - threshold) & (df[\"num_calls\"] <= Q3 + threshold)]\n",
        "\n",
        "# Draw a countplot to visualize the filtered data\n",
        "plt.subplot(433)\n",
        "sns.countplot(x=\"num_calls\", hue=\"y\", data=df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSGT_9VOs-gg"
      },
      "outputs": [],
      "source": [
        "df[\"age\"].unique()\n",
        "df1=df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNKWzQxLO5rt",
        "outputId": "f82a3fa7-7618-4567-bbb7-34b7bc6c08f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'job', 'marital', 'education_qual', 'call_type', 'day', 'mon',\n",
              "       'dur', 'num_calls', 'prev_outcome', 'y', 'z_score'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "\n",
        "df1=df.copy()\n",
        "\n",
        "df1.columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEBF_E_Lia0-",
        "outputId": "2e5930b2-bca1-48eb-fb0e-603ced609e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column \"age\" is divided into \"55\" categories.\n",
            "Column \"job\" is divided into \"11\" categories.\n",
            "Column \"marital\" is divided into \"3\" categories.\n",
            "Column \"education_qual\" is divided into \"3\" categories.\n",
            "Column \"call_type\" is divided into \"2\" categories.\n",
            "Column \"day\" is divided into \"31\" categories.\n",
            "Column \"mon\" is divided into \"12\" categories.\n",
            "Column \"dur\" is divided into \"1027\" categories.\n",
            "Column \"num_calls\" is divided into \"6\" categories.\n",
            "Column \"prev_outcome\" is divided into \"3\" categories.\n",
            "Column \"y\" is divided into \"2\" categories.\n",
            "Column \"z_score\" is divided into \"6\" categories.\n"
          ]
        }
      ],
      "source": [
        "for i in df.columns:\n",
        "  print(f'Column \"{i}\" is divided into \"{len(df[i].value_counts())}\" categories.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKF16bxOkBe5",
        "outputId": "9915e926-29e5-4075-b149-2b48fed5f141"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'job', 'marital', 'education_qual', 'call_type', 'day', 'mon',\n",
              "       'dur', 'num_calls', 'prev_outcome', 'y', 'z_score'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "df1=df\n",
        "df1.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "QFgAz4h-YXKy",
        "outputId": "c45945e0-f007-4438-e679-23feee494c33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G-Test Statistic for job: 698.59\n",
            "P-value (G-Test) for job: 0.0000\n",
            "\n",
            "\n",
            "G-Test Statistic for marital: 208.30\n",
            "P-value (G-Test) for marital: 0.0000\n",
            "\n",
            "\n",
            "G-Test Statistic for education_qual: 281.30\n",
            "P-value (G-Test) for education_qual: 0.0000\n",
            "\n",
            "\n",
            "G-Test Statistic for call_type: 0.55\n",
            "P-value (G-Test) for call_type: 0.4588\n",
            "\n",
            "\n",
            "G-Test Statistic for day: 554.00\n",
            "P-value (G-Test) for day: 0.0000\n",
            "\n",
            "\n",
            "G-Test Statistic for mon: 3028.67\n",
            "P-value (G-Test) for mon: 0.0000\n",
            "\n",
            "\n",
            "G-Test Statistic for prev_outcome: 4475.14\n",
            "P-value (G-Test) for prev_outcome: 0.0000\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nIn this case, the G-test statistic is 4341.70, which is a high value \\nand suggests a significant association between 'prev_outcome' and 'y' variables. \\nThe p-value for the G-test is 0.0000, which is less than the typical significance level of 0.05\\n. This indicates that the\\n observed association is statistically significant\\n , and we can reject the null hypothesis of independence between the two variables.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# create a pandas dataframe with the categorical variables\n",
        "\n",
        "\n",
        "# create a contingency table of the two variables\n",
        "for column in list_cat_vars:\n",
        "      contingency_tab = pd.crosstab(df[column], df1['y'])\n",
        "\n",
        "      # calculate the G-test statistic and p-value\n",
        "      g_stat, p_val, dof, expected_freq = chi2_contingency(contingency_tab)\n",
        "\n",
        "      # print the results\n",
        "      print(f\"G-Test Statistic for {column}: {g_stat:.2f}\")\n",
        "      print(f\"P-value (G-Test) for {column}: {p_val:.4f}\")\n",
        "      print(\"\\n\")\n",
        "\n",
        "\"\"\"\n",
        "In this case, the G-test statistic is 4341.70, which is a high value \n",
        "and suggests a significant association between 'prev_outcome' and 'y' variables. \n",
        "The p-value for the G-test is 0.0000, which is less than the typical significance level of 0.05\n",
        ". This indicates that the\n",
        " observed association is statistically significant\n",
        " , and we can reject the null hypothesis of independence between the two variables.\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISW6Uv3gaLwq"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYy_PPSmZMx0"
      },
      "source": [
        " null hypothesis: there is no association between two columns\n",
        "\n",
        "The p value is less than 0.05 it reject null hypothesis\n",
        "\n",
        "It means that there is strong evidence that there is a significant association between the columns "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hmgm5CHaPfo"
      },
      "source": [
        "the variables with higher G-test statistic values (prev_outcome, mon, day, education_qual) have a stronger association with the outcome than the variables with lower values (call_type, job, marital)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePAe1sB2ZGdv",
        "outputId": "bce74596-f2ff-4fcd-ec2c-09fb63238b6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T-Test Statistic: -0.49\n",
            "P-value (T-Test): 0.6271\n",
            "ANOVA F-Statistic for age: 0.24\n",
            "P-value (ANOVA) for age: 0.6271\n",
            "\n",
            "\n",
            "T-Test Statistic: 77.66\n",
            "P-value (T-Test): 0.0000\n",
            "ANOVA F-Statistic for dur: 6030.52\n",
            "P-value (ANOVA) for dur: 0.0000\n",
            "\n",
            "\n",
            "T-Test Statistic: -14.70\n",
            "P-value (T-Test): 0.0000\n",
            "ANOVA F-Statistic for num_calls: 216.16\n",
            "P-value (ANOVA) for num_calls: 0.0000\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import ttest_ind, f_oneway\n",
        "\n",
        "#df1[\"y\"]=df1[\"y\"].replace({\"1\":\"yes\",\"0\":\"no\"})\n",
        "# create a pandas dataframe with the continuous and categorical variables\n",
        "for column in list_con_vars:\n",
        "          # separate the continuous variable by the categories in the categorical variable\n",
        "          group_A = df.loc[df['y'] == 'yes', column]\n",
        "          group_B = df.loc[df['y'] == 'no', column]\n",
        "\n",
        "          # calculate the t-test statistic and p-value for the two groups\n",
        "          t_stat, p_val = ttest_ind(group_A, group_B)\n",
        "\n",
        "          # print the results\n",
        "          print(f\"T-Test Statistic: {t_stat:.2f}\")\n",
        "          print(f\"P-value (T-Test): {p_val:.4f}\")\n",
        "\n",
        "          # calculate the ANOVA F-statistic and p-value for the two groups\n",
        "          f_stat, p_val = f_oneway(group_A, group_B)\n",
        "\n",
        "          # print the results\n",
        "          print(f\"ANOVA F-Statistic for {column}: {f_stat:.2f}\")\n",
        "          print(f\"P-value (ANOVA) for {column}: {p_val:.4f}\")\n",
        "          print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygei2kL6ZW1m"
      },
      "source": [
        " null hypothesis: there is no association between two columns\n",
        "\n",
        "The p value is less than 0.05 it reject null hypothesis\n",
        "\n",
        "It means that there is strong evidence that there is a significant association between the columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yptYpYEoa0mF"
      },
      "source": [
        "Based on the provided T-test and ANOVA results, the most important factor impacting the outcome variable appears to be the 'dur' variable, with the highest F-statistic value (6668.39) ,Highest T value (81.66) and a very low p-value (0.0000), indicating a strong association between 'dur' and the outcome variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz791ACHkJsB",
        "outputId": "eabc6ec8-2600-4b3a-e83f-161a3b2736da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'dur', 'num_calls', 'z_score', 'job_encoded', 'marital_encoded',\n",
              "       'education_qual_encoded', 'call_type_encoded', 'mon_encoded',\n",
              "       'prev_outcome_encoded', 'y_encoded', 'day_encoded'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Create a LabelEncoder object\n",
        "le = LabelEncoder()\n",
        "df1=pd.DataFrame()\n",
        "# Fit and transform the \"color\" column of the DataFrame\n",
        "df['job_encoded'] = le.fit_transform(df['job'])\n",
        "df['marital_encoded'] = le.fit_transform(df['marital'])\n",
        "df['education_qual_encoded'] = le.fit_transform(df['education_qual'])\n",
        "df['call_type_encoded'] = le.fit_transform(df['call_type'])\n",
        "df['mon_encoded'] = le.fit_transform(df['mon'])\n",
        "df['prev_outcome_encoded'] = le.fit_transform(df['prev_outcome'])\n",
        "df[\"y_encoded\"]=le.fit_transform(df[\"y\"])\n",
        "df[\"day_encoded\"]=le.fit_transform(df[\"day\"])\n",
        "# Print the resulting DataFrame\n",
        "\n",
        "\n",
        "df.drop(columns=['job', 'marital', 'education_qual', 'call_type','prev_outcome',\"mon\",\"y\",\"day\"],inplace=True)\n",
        "\n",
        "\n",
        "df.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgD_MiKRlHYw",
        "outputId": "86229fa0-927d-492c-842c-ef89888074bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.899804257401517\n",
            "Confusion matrix: [[7121  163]\n",
            " [ 656  234]]\n",
            "0.9021776364081233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Load your dataset into a pandas DataFrame or Numpy array\n",
        "X=df.drop(columns=\"y_encoded\",axis=1)\n",
        "y=df[\"y_encoded\"]\n",
        "# Split your dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a logistic regression model object and fit it to the training data\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model using accuracy score and confusion matrix\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion matrix:\", confusion_matrix)\n",
        "print(model.score(X,y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM4GLB8jGT5w",
        "outputId": "5a4f104a-2fe0-4986-a6f2-5297b0f68d3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC: 0.620\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "# Compute AUROC score\n",
        "auroc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print('AUROC: %.3f' % auroc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "J74SYgTxPGgo",
        "outputId": "525e7e66-5bd3-4cd8-a7e7-435f22f285b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          count        mean         std        min  \\\n",
              "age                     40870.0   40.596159   10.125583  18.000000   \n",
              "dur                     40870.0  238.311524  189.965342   0.000000   \n",
              "num_calls               40870.0    2.129875    1.317630   1.000000   \n",
              "z_score                 40870.0   -0.205728    0.423946  -0.569265   \n",
              "job_encoded             40870.0    4.270100    3.256012   0.000000   \n",
              "marital_encoded         40870.0    1.171055    0.609515   0.000000   \n",
              "education_qual_encoded  40870.0    1.144898    0.649148   0.000000   \n",
              "call_type_encoded       40870.0    0.057108    0.232052   0.000000   \n",
              "mon_encoded             40870.0    5.589650    3.005264   0.000000   \n",
              "prev_outcome_encoded    40870.0    0.109494    0.407154   0.000000   \n",
              "y_encoded               40870.0    0.108270    0.310725   0.000000   \n",
              "day_encoded             40870.0   15.410937    8.936709   0.000000   \n",
              "\n",
              "                               25%         50%         75%          max  \n",
              "age                      32.000000   39.000000   48.000000    72.000000  \n",
              "dur                     106.000000  181.000000  310.000000  1030.000000  \n",
              "num_calls                 1.000000    2.000000    3.000000     6.000000  \n",
              "z_score                  -0.569265   -0.247516    0.074233     1.039481  \n",
              "job_encoded               1.000000    4.000000    7.000000    10.000000  \n",
              "marital_encoded           1.000000    1.000000    2.000000     2.000000  \n",
              "education_qual_encoded    1.000000    1.000000    2.000000     2.000000  \n",
              "call_type_encoded         0.000000    0.000000    0.000000     1.000000  \n",
              "mon_encoded               3.000000    6.000000    8.000000    11.000000  \n",
              "prev_outcome_encoded      0.000000    0.000000    0.000000     2.000000  \n",
              "y_encoded                 0.000000    0.000000    0.000000     1.000000  \n",
              "day_encoded               8.000000   13.000000   24.000000    30.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bdfe4464-5a51-43d7-8319-6ec11a28b338\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>40870.0</td>\n",
              "      <td>40.596159</td>\n",
              "      <td>10.125583</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>72.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dur</th>\n",
              "      <td>40870.0</td>\n",
              "      <td>238.311524</td>\n",
              "      <td>189.965342</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>181.000000</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_calls</th>\n",
              "      <td>40870.0</td>\n",
              "      <td>2.129875</td>\n",
              "      <td>1.317630</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>z_score</th>\n",
              "      <td>40870.0</td>\n",
              "      <td>-0.205728</td>\n",
              "      <td>0.423946</td>\n",
              "      <td>-0.569265</td>\n",
              "      <td>-0.569265</td>\n",
              "      <td>-0.247516</td>\n",
              "      <td>0.074233</td>\n",
              "      <td>1.039481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>job_encoded</th>\n",
              "      <td>40870.0</td>\n",
              "      <td>4.270100</td>\n",
              "      <td>3.256012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marital_encoded</th>\n",
              "      <td>40870.0</td>\n",
              "      <td>1.171055</td>\n",
              "      <td>0.609515</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>education_qual_encoded</th>\n",
              "      <td>40870.0</td>\n",
              "      <td>1.144898</td>\n",
              "      <td>0.649148</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>call_type_encoded</th>\n",
              "      <td>40870.0</td>\n",
              "      <td>0.057108</td>\n",
              "      <td>0.232052</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mon_encoded</th>\n",
              "      <td>40870.0</td>\n",
              "      <td>5.589650</td>\n",
              "      <td>3.005264</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>prev_outcome_encoded</th>\n",
              "      <td>40870.0</td>\n",
              "      <td>0.109494</td>\n",
              "      <td>0.407154</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>y_encoded</th>\n",
              "      <td>40870.0</td>\n",
              "      <td>0.108270</td>\n",
              "      <td>0.310725</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>day_encoded</th>\n",
              "      <td>40870.0</td>\n",
              "      <td>15.410937</td>\n",
              "      <td>8.936709</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>30.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdfe4464-5a51-43d7-8319-6ec11a28b338')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bdfe4464-5a51-43d7-8319-6ec11a28b338 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bdfe4464-5a51-43d7-8319-6ec11a28b338');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-MNSvqXS9sp",
        "outputId": "71acb4d4-7228-42d6-c647-9d26c72b6211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8854905798874481\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X=df.drop(columns=\"y_encoded\",axis=1)\n",
        "y=df[\"y_encoded\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the k-NN model\n",
        "k = 5\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "# Train the model\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOI32kBPRfqk",
        "outputId": "943bcc74-db04-4526-925e-29716c2a1b94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC: 0.564\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "# Compute AUROC score\n",
        "auroc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print('AUROC: %.3f' % auroc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvFd4jlfpoUm",
        "outputId": "8c828e9f-c236-4ebd-ea91-2398a4fa7302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree AUROC Score: 0.6951\n",
            "Random Forest AUROC Score: 0.8975\n",
            "SVM AUROC Score: 0.7162\n",
            "Naive Bayes AUROC Score: 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression AUROC Score: 0.8354\n",
            "Gradient Boosting AUROC Score: 0.8995\n",
            "Neural Network AUROC Score: 0.8524\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Load and split the data\n",
        "X = df.drop(columns=\"y_encoded\", axis=1)\n",
        "y = df[\"y_encoded\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the classifiers\n",
        "classifiers = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"SVM\": SVC(probability=True),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"Neural Network\": MLPClassifier()\n",
        "}\n",
        "\n",
        "# Train and evaluate each classifier\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict_proba(X_test)[:, 1]\n",
        "    auc_score = roc_auc_score(y_test, y_pred)\n",
        "    print(f\"{name} AUROC Score: {auc_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxu_ZtQnpLrB",
        "outputId": "30a73d17-424c-4295-e104-9ccb2b32890f"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'dur', 'num_calls', 'z_score', 'job_encoded', 'marital_encoded',\n",
              "       'education_qual_encoded', 'call_type_encoded', 'mon_encoded',\n",
              "       'prev_outcome_encoded', 'y_encoded', 'day_encoded'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4YCVljwdfSl",
        "outputId": "04bb05a2-ac7b-4be3-ad5b-9f03b90ad126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.899804257401517\n",
            "Confusion matrix: [[7121  163]\n",
            " [ 656  234]]\n",
            "0.9021776364081233\n",
            "AUROC: 0.620\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load data and split into X (features) and y (target)\n",
        "X = df.drop(columns=\"y_encoded\", axis=1)\n",
        "y = df[\"y_encoded\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Create logistic regression model with updated parameters\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the model on the scaled data\n",
        "logreg.fit(X_scaled, y)\n",
        "\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model using accuracy score and confusion matrix\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion matrix:\", confusion_matrix)\n",
        "print(model.score(X,y))\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "# Compute AUROC score\n",
        "auroc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print('AUROC: %.3f' % auroc)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paBKauXRe0ka",
        "outputId": "9f75d440-123b-444e-9835-0277b90a5367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC score: 0.8468696974745324\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Load data and split into X (features) and y (target)\n",
        "X = df.drop(columns=\"y_encoded\", axis=1)\n",
        "y = df[\"y_encoded\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Compute class weights to account for class imbalance\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "\n",
        "# Create logistic regression model with updated parameters\n",
        "logreg = LogisticRegression(max_iter=1000, class_weight={0: class_weights[0], 1: class_weights[1]})\n",
        "\n",
        "# Train the model on the training data\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = logreg.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Compute AUROC score\n",
        "auroc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"AUROC score:\", auroc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4N7WZk5i9NP",
        "outputId": "5ab00d13-06dc-4bd7-cd37-01e90a3122eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC score: 0.8872389229278888\n",
            "0.10827012478590653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Load data and split into X (features) and y (target)\n",
        "X = df.drop(columns=\"y_encoded\", axis=1)\n",
        "y = df[\"y_encoded\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Compute class weights to account for class imbalance\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create Gradient Boosting Classifier model with updated parameters\n",
        "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, random_state=42)\n",
        "\n",
        "# Train the model on the training data with sample weights\n",
        "sample_weights = np.array([class_weights[y] for y in y_train])\n",
        "gbc.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = gbc.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Compute AUROC score\n",
        "auroc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"AUROC score:\", auroc)\n",
        "print(gbc.score(X,y))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HYsrniCjzKR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "\n",
        "X = df.drop(columns=\"y_encoded\", axis=1)\n",
        "y = df[\"y_encoded\"]\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Perform feature selection\n",
        "selector = SelectKBest(score_func=mutual_info_classif, k=10)\n",
        "X_selected = selector.fit_transform(X_scaled, y)\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = GradientBoostingClassifier()\n",
        "\n",
        "# Define the hyperparameters to search\n",
        "param_grid = {\n",
        "    \"n_estimators\": [50, 100, 200],\n",
        "    \"learning_rate\": [0.1, 0.05, 0.01],\n",
        "    \"max_depth\": [3, 5, 7]\n",
        "}\n",
        "\n",
        "# Perform grid search to find the best hyperparameters\n",
        "grid_search = GridSearchCV(model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute AUROC score\n",
        "auroc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best model:\", best_model)\n",
        "print(\"AUROC score:\", auroc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcG6WSFSk6Ja"
      },
      "outputs": [],
      "source": [
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_entropy(labels):\n",
        "    unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
        "    probabilities = label_counts / len(labels)\n",
        "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
        "    return entropy\n",
        "\n",
        "def calculate_information_gain(data,target_column):\n",
        "    target_labels = data[target_column]\n",
        "    target_entropy = calculate_entropy(target_labels)\n",
        "    information_gains = {}\n",
        "\n",
        "    for column in data.columns:\n",
        "        if column != target_column:\n",
        "            feature_values = data[column]\n",
        "            unique_values, value_counts = np.unique(feature_values, return_counts=True)\n",
        "            weighted_entropies = []\n",
        "\n",
        "            for value, count in zip(unique_values, value_counts):\n",
        "                subset_labels = target_labels[feature_values == value]\n",
        "                entropy = calculate_entropy(subset_labels)\n",
        "                weighted_entropies.append((count / len(feature_values)) * entropy)\n",
        "\n",
        "            weighted_average_entropy = np.sum(weighted_entropies)\n",
        "            information_gain = target_entropy - weighted_average_entropy\n",
        "            information_gains[column] = information_gain\n",
        "\n",
        "    return information_gains\n",
        "\n",
        "# Example usage\n",
        "# Assuming you have a pandas DataFrame called 'data' with columns and a target variable column called 'target'\n",
        "information_gains = calculate_information_gain(df1, 'y')\n",
        "\n",
        "for i,j in information_gains.items():\n",
        "  print(i,\":\",j)"
      ],
      "metadata": {
        "id": "yuWeEVIGnzxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92df5b60-a6cf-4986-bd83-60569661039c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age : 0.015835993434509033\n",
            "dur : 0.10009175445830054\n",
            "num_calls : 0.004515173372370229\n",
            "z_score : 0.004515173372370229\n",
            "job_encoded : 0.011046841145294417\n",
            "marital_encoded : 0.0035192606777177393\n",
            "education_qual_encoded : 0.004943784345740054\n",
            "call_type_encoded : 1.0474837286000849e-05\n",
            "mon_encoded : 0.03745050313135995\n",
            "prev_outcome_encoded : 0.045606345804299564\n",
            "day_encoded : 0.009351289781692751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The information gain measures the usefulness or importance of a feature/\n",
        "\n",
        "\n",
        "column in predicting the target variable.\n",
        "Higher information gain values indicate that a feature provides more useful information for classification.\n",
        "\n",
        "\n",
        "\n",
        "\"dur\" (duration) and \"prev_outcome\" have the highest information gain values, suggesting they are the most informative features for predicting the target.\n",
        "\n",
        "\n",
        "\"marital\" and \"education_qual\" have relatively low information gain values, indicating they have less predictive power.\n"
      ],
      "metadata": {
        "id": "-QOpUTrIq1V-"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1bnPzBAhxM5mpkPpWW06PEbmc-MA7ka_A",
      "authorship_tag": "ABX9TyPJbgQUccZRanxzO4MSGAYv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}